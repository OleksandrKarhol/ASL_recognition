{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78fd439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# set the graphs to show in the jupyter notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# adds a progressbar\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# set seaborn graphs to a better style\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "import keras\n",
    "keras.__version__\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, Adadelta, RMSprop\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2c9a6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data \n",
    "#shuffle data\n",
    "#split into y/x \n",
    "#split into train and test \n",
    "#encode y labels \n",
    "#build a model \n",
    "#run a model \n",
    "#evaluate \n",
    "#save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b02fe7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53998</th>\n",
       "      <td>Y</td>\n",
       "      <td>0.491100</td>\n",
       "      <td>0.826996</td>\n",
       "      <td>-1.299260e-06</td>\n",
       "      <td>0.366563</td>\n",
       "      <td>0.745827</td>\n",
       "      <td>-0.050008</td>\n",
       "      <td>0.285710</td>\n",
       "      <td>0.628791</td>\n",
       "      <td>-0.080379</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075436</td>\n",
       "      <td>0.760098</td>\n",
       "      <td>0.547673</td>\n",
       "      <td>-0.131350</td>\n",
       "      <td>0.806474</td>\n",
       "      <td>0.496832</td>\n",
       "      <td>-0.140929</td>\n",
       "      <td>0.846854</td>\n",
       "      <td>0.441856</td>\n",
       "      <td>-0.135173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40403</th>\n",
       "      <td>S</td>\n",
       "      <td>0.562349</td>\n",
       "      <td>0.863381</td>\n",
       "      <td>-6.767563e-07</td>\n",
       "      <td>0.495044</td>\n",
       "      <td>0.791981</td>\n",
       "      <td>-0.026944</td>\n",
       "      <td>0.443729</td>\n",
       "      <td>0.717393</td>\n",
       "      <td>-0.049209</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041925</td>\n",
       "      <td>0.656484</td>\n",
       "      <td>0.668333</td>\n",
       "      <td>-0.063937</td>\n",
       "      <td>0.629001</td>\n",
       "      <td>0.715880</td>\n",
       "      <td>-0.046804</td>\n",
       "      <td>0.618677</td>\n",
       "      <td>0.749107</td>\n",
       "      <td>-0.026630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18237</th>\n",
       "      <td>I</td>\n",
       "      <td>0.250759</td>\n",
       "      <td>0.574622</td>\n",
       "      <td>-5.879739e-07</td>\n",
       "      <td>0.169337</td>\n",
       "      <td>0.523644</td>\n",
       "      <td>-0.036972</td>\n",
       "      <td>0.106884</td>\n",
       "      <td>0.438267</td>\n",
       "      <td>-0.055409</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006327</td>\n",
       "      <td>0.257312</td>\n",
       "      <td>0.270694</td>\n",
       "      <td>-0.024642</td>\n",
       "      <td>0.249807</td>\n",
       "      <td>0.221193</td>\n",
       "      <td>-0.024565</td>\n",
       "      <td>0.239658</td>\n",
       "      <td>0.174144</td>\n",
       "      <td>-0.016240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24909</th>\n",
       "      <td>K</td>\n",
       "      <td>0.661325</td>\n",
       "      <td>0.666261</td>\n",
       "      <td>5.183612e-07</td>\n",
       "      <td>0.620992</td>\n",
       "      <td>0.608582</td>\n",
       "      <td>-0.015742</td>\n",
       "      <td>0.616760</td>\n",
       "      <td>0.532263</td>\n",
       "      <td>-0.025623</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049076</td>\n",
       "      <td>0.743674</td>\n",
       "      <td>0.519036</td>\n",
       "      <td>-0.073979</td>\n",
       "      <td>0.714875</td>\n",
       "      <td>0.551055</td>\n",
       "      <td>-0.060267</td>\n",
       "      <td>0.705684</td>\n",
       "      <td>0.580870</td>\n",
       "      <td>-0.041592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26577</th>\n",
       "      <td>L</td>\n",
       "      <td>0.515438</td>\n",
       "      <td>0.899788</td>\n",
       "      <td>1.135414e-07</td>\n",
       "      <td>0.418374</td>\n",
       "      <td>0.896182</td>\n",
       "      <td>-0.048632</td>\n",
       "      <td>0.313544</td>\n",
       "      <td>0.849570</td>\n",
       "      <td>-0.077231</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055731</td>\n",
       "      <td>0.542848</td>\n",
       "      <td>0.686816</td>\n",
       "      <td>-0.099190</td>\n",
       "      <td>0.551430</td>\n",
       "      <td>0.745663</td>\n",
       "      <td>-0.085944</td>\n",
       "      <td>0.554496</td>\n",
       "      <td>0.793940</td>\n",
       "      <td>-0.064152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34700</th>\n",
       "      <td>Q</td>\n",
       "      <td>0.029234</td>\n",
       "      <td>0.616080</td>\n",
       "      <td>7.040018e-07</td>\n",
       "      <td>0.043925</td>\n",
       "      <td>0.621266</td>\n",
       "      <td>-0.065828</td>\n",
       "      <td>0.117935</td>\n",
       "      <td>0.629496</td>\n",
       "      <td>-0.097873</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050653</td>\n",
       "      <td>0.269079</td>\n",
       "      <td>0.676441</td>\n",
       "      <td>-0.078415</td>\n",
       "      <td>0.309944</td>\n",
       "      <td>0.708634</td>\n",
       "      <td>-0.086428</td>\n",
       "      <td>0.340070</td>\n",
       "      <td>0.733694</td>\n",
       "      <td>-0.088558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34915</th>\n",
       "      <td>Q</td>\n",
       "      <td>0.312193</td>\n",
       "      <td>0.544782</td>\n",
       "      <td>1.741863e-06</td>\n",
       "      <td>0.366993</td>\n",
       "      <td>0.611259</td>\n",
       "      <td>-0.163451</td>\n",
       "      <td>0.490807</td>\n",
       "      <td>0.661597</td>\n",
       "      <td>-0.225987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038014</td>\n",
       "      <td>0.723058</td>\n",
       "      <td>0.413354</td>\n",
       "      <td>-0.018468</td>\n",
       "      <td>0.714523</td>\n",
       "      <td>0.476294</td>\n",
       "      <td>-0.037164</td>\n",
       "      <td>0.687471</td>\n",
       "      <td>0.502014</td>\n",
       "      <td>-0.035660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19949</th>\n",
       "      <td>I</td>\n",
       "      <td>0.212166</td>\n",
       "      <td>0.959157</td>\n",
       "      <td>-4.874714e-07</td>\n",
       "      <td>0.139144</td>\n",
       "      <td>0.916790</td>\n",
       "      <td>-0.020007</td>\n",
       "      <td>0.104880</td>\n",
       "      <td>0.834984</td>\n",
       "      <td>-0.033459</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038584</td>\n",
       "      <td>0.309114</td>\n",
       "      <td>0.687479</td>\n",
       "      <td>-0.060470</td>\n",
       "      <td>0.316068</td>\n",
       "      <td>0.633678</td>\n",
       "      <td>-0.064158</td>\n",
       "      <td>0.321095</td>\n",
       "      <td>0.584429</td>\n",
       "      <td>-0.061633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6739</th>\n",
       "      <td>D</td>\n",
       "      <td>0.523529</td>\n",
       "      <td>0.652290</td>\n",
       "      <td>-7.667634e-08</td>\n",
       "      <td>0.408075</td>\n",
       "      <td>0.575278</td>\n",
       "      <td>0.046501</td>\n",
       "      <td>0.345407</td>\n",
       "      <td>0.514470</td>\n",
       "      <td>0.037550</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099222</td>\n",
       "      <td>0.441690</td>\n",
       "      <td>0.306186</td>\n",
       "      <td>-0.114212</td>\n",
       "      <td>0.374689</td>\n",
       "      <td>0.300663</td>\n",
       "      <td>-0.111589</td>\n",
       "      <td>0.328549</td>\n",
       "      <td>0.323968</td>\n",
       "      <td>-0.107837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42685</th>\n",
       "      <td>T</td>\n",
       "      <td>0.415799</td>\n",
       "      <td>0.928946</td>\n",
       "      <td>-5.892481e-07</td>\n",
       "      <td>0.308014</td>\n",
       "      <td>0.906056</td>\n",
       "      <td>-0.050676</td>\n",
       "      <td>0.201152</td>\n",
       "      <td>0.846537</td>\n",
       "      <td>-0.079211</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048974</td>\n",
       "      <td>0.475879</td>\n",
       "      <td>0.668577</td>\n",
       "      <td>-0.097461</td>\n",
       "      <td>0.474089</td>\n",
       "      <td>0.739336</td>\n",
       "      <td>-0.079902</td>\n",
       "      <td>0.465714</td>\n",
       "      <td>0.788736</td>\n",
       "      <td>-0.053400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59321 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Labels         0         1             2         3         4         5  \\\n",
       "53998      Y  0.491100  0.826996 -1.299260e-06  0.366563  0.745827 -0.050008   \n",
       "40403      S  0.562349  0.863381 -6.767563e-07  0.495044  0.791981 -0.026944   \n",
       "18237      I  0.250759  0.574622 -5.879739e-07  0.169337  0.523644 -0.036972   \n",
       "24909      K  0.661325  0.666261  5.183612e-07  0.620992  0.608582 -0.015742   \n",
       "26577      L  0.515438  0.899788  1.135414e-07  0.418374  0.896182 -0.048632   \n",
       "...      ...       ...       ...           ...       ...       ...       ...   \n",
       "34700      Q  0.029234  0.616080  7.040018e-07  0.043925  0.621266 -0.065828   \n",
       "34915      Q  0.312193  0.544782  1.741863e-06  0.366993  0.611259 -0.163451   \n",
       "19949      I  0.212166  0.959157 -4.874714e-07  0.139144  0.916790 -0.020007   \n",
       "6739       D  0.523529  0.652290 -7.667634e-08  0.408075  0.575278  0.046501   \n",
       "42685      T  0.415799  0.928946 -5.892481e-07  0.308014  0.906056 -0.050676   \n",
       "\n",
       "              6         7         8  ...        53        54        55  \\\n",
       "53998  0.285710  0.628791 -0.080379  ... -0.075436  0.760098  0.547673   \n",
       "40403  0.443729  0.717393 -0.049209  ... -0.041925  0.656484  0.668333   \n",
       "18237  0.106884  0.438267 -0.055409  ... -0.006327  0.257312  0.270694   \n",
       "24909  0.616760  0.532263 -0.025623  ... -0.049076  0.743674  0.519036   \n",
       "26577  0.313544  0.849570 -0.077231  ... -0.055731  0.542848  0.686816   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "34700  0.117935  0.629496 -0.097873  ... -0.050653  0.269079  0.676441   \n",
       "34915  0.490807  0.661597 -0.225987  ...  0.038014  0.723058  0.413354   \n",
       "19949  0.104880  0.834984 -0.033459  ... -0.038584  0.309114  0.687479   \n",
       "6739   0.345407  0.514470  0.037550  ... -0.099222  0.441690  0.306186   \n",
       "42685  0.201152  0.846537 -0.079211  ... -0.048974  0.475879  0.668577   \n",
       "\n",
       "             56        57        58        59        60        61        62  \n",
       "53998 -0.131350  0.806474  0.496832 -0.140929  0.846854  0.441856 -0.135173  \n",
       "40403 -0.063937  0.629001  0.715880 -0.046804  0.618677  0.749107 -0.026630  \n",
       "18237 -0.024642  0.249807  0.221193 -0.024565  0.239658  0.174144 -0.016240  \n",
       "24909 -0.073979  0.714875  0.551055 -0.060267  0.705684  0.580870 -0.041592  \n",
       "26577 -0.099190  0.551430  0.745663 -0.085944  0.554496  0.793940 -0.064152  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "34700 -0.078415  0.309944  0.708634 -0.086428  0.340070  0.733694 -0.088558  \n",
       "34915 -0.018468  0.714523  0.476294 -0.037164  0.687471  0.502014 -0.035660  \n",
       "19949 -0.060470  0.316068  0.633678 -0.064158  0.321095  0.584429 -0.061633  \n",
       "6739  -0.114212  0.374689  0.300663 -0.111589  0.328549  0.323968 -0.107837  \n",
       "42685 -0.097461  0.474089  0.739336 -0.079902  0.465714  0.788736 -0.053400  \n",
       "\n",
       "[59321 rows x 64 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data \n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "directory = 'datasets/dataset_cleaned.csv'\n",
    "data = pd.read_csv(directory)\n",
    "data['Labels'] = data['Labels'].replace(['del'],'.')\n",
    "del data['Unnamed: 0']\n",
    "data = shuffle(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e388cbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into y/x \n",
    "\n",
    "y_data = np.array((data['Labels']))\n",
    "x_data = data.drop('Labels', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cea98ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Y', 'S', 'I', ..., 'I', 'D', 'T'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "640c2a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 63) (49321, 63) (10000, 28) (49321, 28)\n"
     ]
    }
   ],
   "source": [
    "#split into train and test \n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_data)\n",
    "encoded_y = encoder.transform(y_data)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_y)\n",
    "\n",
    "threshold = 10000 # len(y_data)/5\n",
    "\n",
    "x_test = x_data[:threshold]\n",
    "x_train = x_data[threshold:]\n",
    "\n",
    "y_test = dummy_y[:threshold]\n",
    "y_train = dummy_y[threshold:]\n",
    "\n",
    "print(x_test.shape, x_train.shape, y_test.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b45b2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 60)                3840      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 15)                915       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 15)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 28)                448       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,203\n",
      "Trainable params: 5,203\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 21:56:47.610319: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/apple/opt/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(60, input_shape = (63,), activation = \"swish\"))\n",
    "model.add(Dense(15, activation = \"swish\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(28, activation = \"softmax\"))\n",
    "model.compile(Adam(lr = 0.01), \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1607ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1542/1542 [==============================] - 3s 2ms/step - loss: 0.8384 - accuracy: 0.7291 - val_loss: 0.2926 - val_accuracy: 0.9145\n",
      "Epoch 2/30\n",
      "1542/1542 [==============================] - 2s 1ms/step - loss: 0.3347 - accuracy: 0.8966 - val_loss: 0.2811 - val_accuracy: 0.8776\n",
      "Epoch 3/30\n",
      "1542/1542 [==============================] - 2s 2ms/step - loss: 0.2704 - accuracy: 0.9158 - val_loss: 0.1108 - val_accuracy: 0.9725\n",
      "Epoch 4/30\n",
      "1542/1542 [==============================] - 3s 2ms/step - loss: 0.2322 - accuracy: 0.9267 - val_loss: 0.1046 - val_accuracy: 0.9724\n",
      "Epoch 5/30\n",
      "1542/1542 [==============================] - 2s 1ms/step - loss: 0.2191 - accuracy: 0.9316 - val_loss: 0.1068 - val_accuracy: 0.9668\n",
      "Epoch 6/30\n",
      "1542/1542 [==============================] - 2s 1ms/step - loss: 0.2022 - accuracy: 0.9382 - val_loss: 0.1735 - val_accuracy: 0.9282\n",
      "Epoch 7/30\n",
      "1542/1542 [==============================] - 3s 2ms/step - loss: 0.1924 - accuracy: 0.9417 - val_loss: 0.0882 - val_accuracy: 0.9731\n",
      "Epoch 8/30\n",
      "1542/1542 [==============================] - 2s 2ms/step - loss: 0.1847 - accuracy: 0.9435 - val_loss: 0.1076 - val_accuracy: 0.9650\n",
      "Epoch 9/30\n",
      "1542/1542 [==============================] - 2s 1ms/step - loss: 0.1692 - accuracy: 0.9492 - val_loss: 0.1110 - val_accuracy: 0.9706\n",
      "Epoch 10/30\n",
      "1542/1542 [==============================] - 2s 1ms/step - loss: 0.1611 - accuracy: 0.9520 - val_loss: 0.0676 - val_accuracy: 0.9805\n",
      "Epoch 11/30\n",
      "1542/1542 [==============================] - 2s 1ms/step - loss: 0.1615 - accuracy: 0.9523 - val_loss: 0.0853 - val_accuracy: 0.9716\n",
      "Epoch 12/30\n",
      "1542/1542 [==============================] - 2s 2ms/step - loss: 0.1541 - accuracy: 0.9536 - val_loss: 0.0820 - val_accuracy: 0.9740\n",
      "Epoch 13/30\n",
      "1542/1542 [==============================] - 2s 1ms/step - loss: 0.1470 - accuracy: 0.9558 - val_loss: 0.0725 - val_accuracy: 0.9742\n",
      "Epoch 14/30\n",
      "1542/1542 [==============================] - 2s 1ms/step - loss: 0.1528 - accuracy: 0.9544 - val_loss: 0.0916 - val_accuracy: 0.9736\n",
      "Epoch 15/30\n",
      "1542/1542 [==============================] - 2s 1ms/step - loss: 0.1358 - accuracy: 0.9595 - val_loss: 0.0697 - val_accuracy: 0.9793\n",
      "Epoch 16/30\n",
      "1542/1542 [==============================] - 2s 1ms/step - loss: 0.1424 - accuracy: 0.9574 - val_loss: 0.0682 - val_accuracy: 0.9822\n",
      "Epoch 17/30\n",
      "1542/1542 [==============================] - 2s 1ms/step - loss: 0.1351 - accuracy: 0.9606 - val_loss: 0.0758 - val_accuracy: 0.9783\n",
      "Epoch 18/30\n",
      "1542/1542 [==============================] - 2s 1ms/step - loss: 0.1335 - accuracy: 0.9605 - val_loss: 0.0659 - val_accuracy: 0.9809\n",
      "Epoch 19/30\n",
      "1542/1542 [==============================] - 2s 1ms/step - loss: 0.1344 - accuracy: 0.9612 - val_loss: 0.1228 - val_accuracy: 0.9636\n",
      "Epoch 20/30\n",
      "1542/1542 [==============================] - 3s 2ms/step - loss: 0.1284 - accuracy: 0.9623 - val_loss: 0.0626 - val_accuracy: 0.9793\n",
      "Epoch 21/30\n",
      "1542/1542 [==============================] - 2s 1ms/step - loss: 0.1294 - accuracy: 0.9625 - val_loss: 0.0649 - val_accuracy: 0.9803\n",
      "Epoch 22/30\n",
      "1542/1542 [==============================] - 2s 1ms/step - loss: 0.1256 - accuracy: 0.9643 - val_loss: 0.0531 - val_accuracy: 0.9854\n",
      "Epoch 23/30\n",
      "1542/1542 [==============================] - 2s 1ms/step - loss: 0.1219 - accuracy: 0.9644 - val_loss: 0.0478 - val_accuracy: 0.9845\n",
      "Epoch 24/30\n",
      "1542/1542 [==============================] - 2s 1ms/step - loss: 0.1276 - accuracy: 0.9641 - val_loss: 0.0382 - val_accuracy: 0.9890\n",
      "Epoch 25/30\n",
      "1542/1542 [==============================] - 2s 1ms/step - loss: 0.1193 - accuracy: 0.9658 - val_loss: 0.1024 - val_accuracy: 0.9712\n",
      "Epoch 26/30\n",
      "1542/1542 [==============================] - 2s 1ms/step - loss: 0.1161 - accuracy: 0.9673 - val_loss: 0.0607 - val_accuracy: 0.9829\n",
      "Epoch 27/30\n",
      "1542/1542 [==============================] - 2s 1ms/step - loss: 0.1233 - accuracy: 0.9655 - val_loss: 0.0532 - val_accuracy: 0.9859\n",
      "Epoch 28/30\n",
      "1542/1542 [==============================] - 2s 1ms/step - loss: 0.1219 - accuracy: 0.9653 - val_loss: 0.0881 - val_accuracy: 0.9753\n",
      "Epoch 29/30\n",
      "1542/1542 [==============================] - 2s 1ms/step - loss: 0.1065 - accuracy: 0.9705 - val_loss: 0.0569 - val_accuracy: 0.9843\n",
      "Epoch 30/30\n",
      "1542/1542 [==============================] - 2s 1ms/step - loss: 0.1109 - accuracy: 0.9684 - val_loss: 0.0845 - val_accuracy: 0.9773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe9bdf92dc0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=30, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c103575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,  13,   0,   0,   0,   1,  39,   0,   0,   0,   0,\n",
       "          0,   0,  40,   0,   6,   0,  53,   0,  80,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   2,   0, 196,   0, 161,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0, 150,   0, 189,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0, 107,   0, 165,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [ 16,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0, 196,   0, 179,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0, 189,   0, 212,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0, 185,   0, 289,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   6,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  56,   0,   2,   0, 130,   0, 190,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   7,   0, 192,   0, 183,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   2,   0, 291,   0,  70,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   2,   0, 148,   0, 264,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0, 161,   0, 302,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0, 235,   0, 152,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   1,   0,  58,   0,  41,   0, 108,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   1,   0,  31,   0,  26,   0,  88,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [ 24,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0, 208,   0, 133,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,  74,   0,   0,   0,   3,  73,   0,   0,   0,   0,\n",
       "          2,   0,   6,   0,  26,   0, 117,   0,  21,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,  14,   0,   0,   0,   0,  71,   0,   0,   0,   0,\n",
       "         41,   0,   0,   0,  19,   0, 139,   0,  40,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0, 213,   0, 235,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   3,   0, 170,   0, 216,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   7,   0, 246,   0, 133,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0, 186,   0, 219,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0, 119,   0, 289,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   1,   0, 120,   0, 273,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   4,   0,  11,   0, 193,   0, 143,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0, 252,   0, 199,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0, 182,   0, 168,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,   0,\n",
       "          0,   0,   1,   0,   0,   0,  62,   0, 112,   0,   0,   0,   0,\n",
       "          0,   0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model.predict(x_test)\n",
    "y_test_class = np.argmax(y_test, axis=1)\n",
    "y_pred_class = np.argmax(y_pred, axis=1)\n",
    "confusion_matrix(y_test_class, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a67e68af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95       212\n",
      "           1       1.00      0.98      0.99       344\n",
      "           2       1.00      1.00      1.00       342\n",
      "           3       0.97      1.00      0.98       303\n",
      "           4       1.00      0.95      0.97       336\n",
      "           5       0.88      1.00      0.94       366\n",
      "           6       1.00      1.00      1.00       427\n",
      "           7       0.97      1.00      0.98       441\n",
      "           8       0.98      0.98      0.98       398\n",
      "           9       0.98      0.97      0.98       393\n",
      "          10       1.00      0.96      0.98       400\n",
      "          11       1.00      0.98      0.99       433\n",
      "          12       1.00      1.00      1.00       434\n",
      "          13       0.77      1.00      0.87       212\n",
      "          14       1.00      0.62      0.76       169\n",
      "          15       0.97      0.99      0.98       383\n",
      "          16       1.00      0.97      0.98       339\n",
      "          17       1.00      0.98      0.99       335\n",
      "          18       1.00      0.98      0.99       398\n",
      "          19       0.99      0.89      0.94       393\n",
      "          20       0.99      0.99      0.99       339\n",
      "          21       0.98      0.99      0.98       442\n",
      "          22       0.97      1.00      0.98       438\n",
      "          23       0.99      0.99      0.99       383\n",
      "          24       0.97      0.99      0.98       366\n",
      "          25       1.00      1.00      1.00       423\n",
      "          26       1.00      0.99      1.00       379\n",
      "          27       0.99      1.00      0.99       172\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.97      0.97     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91b8d38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 21:39:53.501359: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_A5.tf/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('model.tf', include_optimizer = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37e0b89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
